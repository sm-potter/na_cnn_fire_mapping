{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "aea058c7-f678-44d5-937d-9cc4ffb74b50",
   "metadata": {},
   "source": [
    "This script will download all the nbac or mtbs polygons to a google cloud storage bucket.  It will be used for training.  image compositing method uses monthly in a range of months april-May all the way to September to October.  Old dNBR method also used.  85%  percentile of values retained to avoid using outliers. tif files saved to a google cloud storage bucket"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74ce429d-af33-40fd-8638-e62ffa201576",
   "metadata": {},
   "source": [
    "Read in all the packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5183878f-0f72-42ec-84f0-8fda2b884ac8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/spotter5/.conda/envs/gee_ml/lib/python3.10/site-packages/pandas/core/arrays/masked.py:60: UserWarning: Pandas requires version '1.3.6' or newer of 'bottleneck' (version '1.3.5' currently installed).\n",
      "  from pandas.core import (\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import ee\n",
    "import numpy as np\n",
    "from geeml.extract import extractor\n",
    "import pandas as pd\n",
    "import random\n",
    "\n",
    "\n",
    "# os.environ[\"GOOGLE_APPLICATION_CREDENTIALS\"] = \"my_json\" #replace this with pathway to json credentials. \n",
    "\n",
    "# service_account = 'my_service_account'\n",
    "# credentials = ee.ServiceAccountCredentials(service_account, \"my_json\")\n",
    "\n",
    "# ee.Initialize(credentials)#h high-volume end-point\n",
    "# ee.Initialize(opt_url='https://earthengine-highvolume.googleapis.com')\n",
    "\n",
    "\n",
    "\n",
    "os.environ[\"GOOGLE_APPLICATION_CREDENTIALS\"] = \"/explore/nobackup/people/spotter5/cnn_mapping/gee-serdp-upload-7cd81da3dc69.json\"\n",
    "\n",
    "service_account = 'gee-serdp-upload@appspot.gserviceaccount.com'\n",
    "credentials = ee.ServiceAccountCredentials(service_account, \"/explore/nobackup/people/spotter5/cnn_mapping/gee-serdp-upload-7cd81da3dc69.json\")\n",
    "ee.Initialize(credentials)\n",
    "# Initialize GEE with high-volume end-point\n",
    "# ee.Initialize(opt_url='https://earthengine-highvolume.googleapis.com')\n",
    "ee.Initialize()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "19813541-9f8c-4105-9a4b-e1fbf218ac7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import geemap\n",
    "from google.cloud import storage\n",
    "from google.cloud import client"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7079fbd-131b-4590-a7c0-95b1b658bc75",
   "metadata": {},
   "source": [
    "Read in assets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "112d5a6a-b286-4cc1-8e72-242e93a52be8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sent_2A = ee.ImageCollection(\"COPERNICUS/S2_SR_HARMONIZED\") #sentinel 2\n",
    "s2Clouds = ee.ImageCollection('COPERNICUS/S2_CLOUD_PROBABILITY') #cloud masking for sentinel\n",
    "lfdb = ee.FeatureCollection(\"users/spotter/fire_cnn/ann_w_id\") #anna polygons \n",
    "lfdb = ee.FeatureCollection(\"users/spotter/fire_cnn/raw/nbac_1985\") #nbac_fire_polygons, this can be any polygon shapefile, final version would be nbac and mtbs\n",
    "# lfdb = ee.FeatureCollection(\"users/spotter/fire_cnn/raw/ak_mtbs_1985\") #nbac_fire_polygons, this can be any polygon shapefile, final version would be nbac and mtbs\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88507678-1d1d-4e8a-b35f-04dc676ddda9",
   "metadata": {},
   "source": [
    "Mask clouds Sentinel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3e5ec6b5-f3ea-416d-ab22-25ec553a89d7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "#probability of clouds\n",
    "MAX_CLOUD_PROBABILITY = 50\n",
    "\n",
    "def sent_maskcloud(image):\n",
    "    \n",
    "    \n",
    "    image = image.select(['B2', 'B3', 'B4', 'B8', 'B11', 'B12'], ['SR_B1', 'SR_B2', 'SR_B3', 'SR_B4', 'SR_B5', 'SR_B7'])# rename bands to match landsat\n",
    "  \n",
    "    image =  image.toShort()\n",
    "    \n",
    "    clouds = ee.Image(image.get('cloud_mask')).select('probability')\n",
    "    \n",
    "    isNotCloud = clouds.lt(MAX_CLOUD_PROBABILITY)\n",
    "    \n",
    "    image = image.updateMask(isNotCloud)\n",
    "\n",
    "    #reproject 30m but remember b1, b2 and b3 are 10 and the rest are 20\n",
    "    image1 = image.select(['SR_B1', 'SR_B2', 'SR_B3', 'SR_B4'])\n",
    "    image2 = image.select(['SR_B5', 'SR_B7'])\n",
    "\n",
    "    \n",
    "    image1 = image1.reproject(\n",
    "    crs = image1.projection().crs(),\n",
    "    scale = 30) #resample for landsat\n",
    "    \n",
    "    \n",
    "    image2 = image2.reproject(\n",
    "    crs = image2.projection().crs(),\n",
    "    scale = 30) #resample for landsat\n",
    "    \n",
    "    image = image1.addBands(image2)\n",
    "    \n",
    "    return image \n",
    "\n",
    "#Join S2 SR with cloud probability dataset to add cloud mask.\n",
    "s2SrWithCloudMask = ee.Join.saveFirst('cloud_mask').apply(\n",
    "    \n",
    "  primary=sent_2A,\n",
    "  secondary=s2Clouds,\n",
    "  condition=ee.Filter.equals(leftField='system:index', rightField='system:index'))\n",
    "\n",
    "#apply cloud masking\n",
    "sent_2A = ee.ImageCollection(s2SrWithCloudMask).map(sent_maskcloud)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c863fb50-782b-4b7a-b25a-94d3d51ca032",
   "metadata": {},
   "source": [
    "Landsat Mask, snow and clouds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "35acd43f-65a9-46cf-9200-ef3591158bd0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def mask(image):\n",
    "    qa = image.select('QA_PIXEL')                                       \n",
    "    mask = qa.bitwiseAnd(8).eq(0).And(qa.bitwiseAnd(10).eq(0)).And(qa.bitwiseAnd(32).eq(0))  \n",
    "    return(image.updateMask(mask))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f46e3b4-715f-4518-ae64-e6c60d08f37b",
   "metadata": {},
   "source": [
    "Correct the landsat scale factor and sentinel scale factor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e0d1682d-8ad7-409f-918c-0c5fe6a46cd8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def land_scale(image):\n",
    "\n",
    "    return(image.multiply(0.0000275).add(-0.2))\n",
    "\n",
    "def sent_scale(image):\n",
    "    return(image.multiply(0.0001))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "926c4ebf-0107-43e7-b251-5ec6ebeb58f2",
   "metadata": {},
   "source": [
    "Coefficients from Logan Berner to apply correction factors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e4fc86e6-ea59-4ceb-9325-1133d5822a41",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3456733/639313901.py:18: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  l5['band.or.si']=pd.Categorical(l5['band.or.si'],categories=bands)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "coeffs = pd.read_csv(\"/explore/nobackup/people/spotter5/cnn_mapping/raw_files/boreal_xcal_regression_coefficients.csv\").fillna(0)\n",
    "\n",
    "#l5\n",
    "def landsat_correct(sat, bands):\n",
    "\n",
    "    \"\"\"argument 1 is which sattelite, LANDASAT_5 or LANDSAT_8\n",
    "    argument 2 is bands of interest.  Bands must be in same order as EE,\n",
    "    \n",
    "    regression is of form,\n",
    "    L7 = B0 + (B1 * L5/8) + (B2 * L^2) + (B3 * L^3)\n",
    "    \"\"\"\n",
    "\n",
    "    #bands of interest in order of interest\n",
    "    l5 = coeffs[(coeffs['satellite'] == sat) & (coeffs['band.or.si'] .isin (bands))] \n",
    "\n",
    "    #arrange the band or si column\n",
    "    l5['band.or.si']=pd.Categorical(l5['band.or.si'],categories=bands)\n",
    "    l5=l5.sort_values('band.or.si')\n",
    "\n",
    "    b0 = l5['B0'].values.tolist()\n",
    "    b1 = l5['B1'].values.tolist()\n",
    "    b2 = l5['B2'].values.tolist()\n",
    "    b3 = l5['B3'].values.tolist()\n",
    "\n",
    "    return (b0, b1, b2, b3)\n",
    "\n",
    "#get the corrections, each output is a list at one of the four locations\n",
    "l8_corr = landsat_correct(sat = 'LANDSAT_8', bands = ['blue', 'green', 'red', 'nir', 'swir1', 'swir2', 'nbr', 'ndvi', 'ndii'])\n",
    "l5_corr = landsat_correct(sat = 'LANDSAT_5', bands = ['blue', 'green', 'red', 'nir', 'swir1', 'swir2', 'nbr', 'ndvi', 'ndii'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0793967d-7d8a-4816-b08a-e5802713a298",
   "metadata": {},
   "source": [
    "Authenticate my google bucket, not sure if this is needed anymore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a0cf79c3-321c-4b93-8e1e-d019ea137db8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# os.environ[\"GOOGLE_APPLICATION_CREDENTIALS\"] = \"my_json\"\n",
    "# storage_client = storage.Client.from_service_account_json(\"my_json\")\n",
    "\n",
    "# os.environ[\"GCLOUD_PROJECT\"] = \"gee-serdp-upload\"\n",
    "# storage_client = storage.Client()\n",
    "# # bucket_name = 'smp-scratch/mtbs_1985'\n",
    "# bucket_name = 'smp-scratch'\n",
    "\n",
    "# bucket = storage_client.bucket(bucket_name)\n",
    "\n",
    "os.environ[\"GCLOUD_PROJECT\"] = \"gee-serdp-upload\"\n",
    "\n",
    "os.environ[\"GOOGLE_APPLICATION_CREDENTIALS\"] = \"/explore/nobackup/people/spotter5/cnn_mapping/gee-serdp-upload-7cd81da3dc69.json\"\n",
    "storage_client = storage.Client.from_service_account_json(\"/explore/nobackup/people/spotter5/cnn_mapping/gee-serdp-upload-7cd81da3dc69.json\")\n",
    "\n",
    "os.environ[\"GCLOUD_PROJECT\"] = \"gee-serdp-upload\"\n",
    "storage_client = storage.Client()\n",
    "# bucket_name = 'smp-scratch/mtbs_1985'\n",
    "bucket_name = 'smp-scratch'\n",
    "\n",
    "bucket = storage_client.bucket(bucket_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81e37cae-c880-4a4f-a988-c304f5a1f9b9",
   "metadata": {},
   "source": [
    "There are going to be issues later with different band types, so cast them all to float"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b823b48d-3592-44ba-a643-a12f2c54326c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def to_float(image):\n",
    "\n",
    "    b1 = image.select('SR_B1').cast({'SR_B1':'float'}) #0\n",
    "    b2 = image.select('SR_B2').cast({'SR_B2':'float'}) #1\n",
    "    b3 = image.select('SR_B3').cast({'SR_B3':'float'}) #2\n",
    "    b4 = image.select('SR_B4').cast({'SR_B4':'float'}) #3\n",
    "    b5 = image.select('SR_B5').cast({'SR_B5':'float'}) #4\n",
    "    b6 = image.select('SR_B7').cast({'SR_B7':'float'}) #5\n",
    "\n",
    "    image = b1.addBands(b2).addBands(b3).addBands(b4).addBands(b5).addBands(b6)\n",
    "\n",
    "    return image"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8e6a5b3-58f5-4fcc-b389-3a57e40dbb74",
   "metadata": {},
   "source": [
    "Function to get pre and post fire imagery for a range of dates. returns a list of images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "de646385-37f0-472d-9206-3bd01e13f65f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pre_post(pre_start, pre_end, post_start, post_end, geometry):\n",
    "\n",
    "    \"\"\"parameters are:\n",
    "    pre_start: the start date for pre fire imagery\n",
    "    pre_end: the end date for pre fire imagery\n",
    "    post_start: the start date for post fire imagery\n",
    "    post_end: the end date for post_fire imagery\n",
    "    geometry: the geometry to filter by\n",
    "    returns: list of images\n",
    "    \"\"\"\n",
    "\n",
    "    #landsat 5\n",
    "    lt5 = ee.ImageCollection('LANDSAT/LT05/C02/T1_L2').filterDate(pre_start, post_end).filterBounds(geometry)\n",
    "    #landsat 7\n",
    "    le7 = ee.ImageCollection('LANDSAT/LE07/C02/T1_L2').filterDate(pre_start, post_end).filterBounds(geometry)\n",
    "    #landsat 8\n",
    "    lc8 = ee.ImageCollection('LANDSAT/LC08/C02/T1_L2').filterDate(pre_start, post_end).filterBounds(geometry)\n",
    "    #sentinel 2\n",
    "    sent = sent_2A.filterDate(pre_start, post_end).filterBounds(geometry)\n",
    "\n",
    "    #select bands\n",
    "    pre_lt5 = lt5.filterDate(pre_start, pre_end).map(mask).map(land_scale).select(['SR_B1', 'SR_B2', 'SR_B3', 'SR_B4', 'SR_B5', 'SR_B7']).map(to_float)\n",
    "\n",
    "    #       #ensure we have imagery for the sensor\n",
    "    if pre_lt5.size().getInfo() > 0 :\n",
    "\n",
    "\n",
    "        #take the median\n",
    "        pre_lt5 = pre_lt5.median().clip(geometry)\n",
    "\n",
    "        #calculate nbr, ndvi and ndii\n",
    "        pre_lt5_nbr = pre_lt5.normalizedDifference(['SR_B4', 'SR_B7']).select([0], ['NBR']).cast({'NBR': 'float'})\n",
    "        pre_lt5_ndvi = pre_lt5.normalizedDifference(['SR_B4', 'SR_B3']).select([0], ['NDVI']).cast({'NDVI': 'float'})\n",
    "        pre_lt5_ndii = pre_lt5.normalizedDifference(['SR_B4', 'SR_B5']).select([0], ['NDII']).cast({'NDII': 'float'})\n",
    "\n",
    "        #add the bands back\n",
    "        pre_lt5 = pre_lt5.addBands(pre_lt5_nbr).addBands(pre_lt5_ndvi).addBands(pre_lt5_ndii)\n",
    "\n",
    "        #apply the corrections\n",
    "\n",
    "        l5_pre_corr = pre_lt5.multiply(l5_corr[1]).add(pre_lt5.pow(2).multiply(l5_corr[2])).add(pre_lt5.pow(3).multiply(l5_corr[3])).add(l5_corr[0])\n",
    "\n",
    "    #-------now do post-fire\n",
    "    #select bands\n",
    "    post_lt5 = lt5.filterDate(post_start, post_end).map(mask).map(land_scale).select(['SR_B1', 'SR_B2', 'SR_B3', 'SR_B4', 'SR_B5', 'SR_B7']).map(to_float)\n",
    "\n",
    "    #       #ensure we have imagery for the sensor\n",
    "    if post_lt5.size().getInfo() > 0 :\n",
    "\n",
    "\n",
    "\n",
    "        #take the median\n",
    "        post_lt5 = post_lt5.median().clip(geometry)\n",
    "\n",
    "        #calculate nbr, ndvi and ndii\n",
    "        post_lt5_nbr = post_lt5.normalizedDifference(['SR_B4', 'SR_B7']).select([0], ['NBR']).cast({'NBR': 'float'})\n",
    "        post_lt5_ndvi = post_lt5.normalizedDifference(['SR_B4', 'SR_B3']).select([0], ['NDVI']).cast({'NDVI': 'float'})\n",
    "        post_lt5_ndii = post_lt5.normalizedDifference(['SR_B4', 'SR_B5']).select([0], ['NDII']).cast({'NDII': 'float'})\n",
    "\n",
    "        #add the bands back\n",
    "        post_lt5 = post_lt5.addBands(post_lt5_nbr).addBands(post_lt5_ndvi).addBands(post_lt5_ndii)\n",
    "\n",
    "        #apply the corrections\n",
    "\n",
    "        l5_post_corr = post_lt5.multiply(l5_corr[1]).add(post_lt5.pow(2).multiply(l5_corr[2])).add(post_lt5.pow(3).multiply(l5_corr[3])).add(l5_corr[0])\n",
    "\n",
    "\n",
    "      #         #------------------------------------------Landsat 7, no corrections but get things clipped and do pre fire/post_fire stuff\n",
    "\n",
    "\n",
    "    #select bands\n",
    "    pre_le7 = le7.filterDate(pre_start, pre_end).map(mask).map(land_scale).select(['SR_B1', 'SR_B2', 'SR_B3', 'SR_B4', 'SR_B5', 'SR_B7']).map(to_float)\n",
    "\n",
    "    #       #ensure we have imagery for the sensor\n",
    "    if pre_le7.size().getInfo() > 0 :\n",
    "\n",
    "\n",
    "\n",
    "        #take the median\n",
    "        pre_le7 = pre_le7.median().clip(geometry)\n",
    "\n",
    "        #calculate nbr, ndvi and ndii\n",
    "        pre_le7_nbr = pre_le7.normalizedDifference(['SR_B4', 'SR_B7']).select([0], ['NBR']).cast({'NBR': 'float'})\n",
    "        pre_le7_ndvi = pre_le7.normalizedDifference(['SR_B4', 'SR_B3']).select([0], ['NDVI']).cast({'NDVI': 'float'})\n",
    "        pre_le7_ndii = pre_le7.normalizedDifference(['SR_B4', 'SR_B5']).select([0], ['NDII']).cast({'NDII': 'float'})\n",
    "\n",
    "        #add the bands back\n",
    "        pre_le72 = pre_le7.addBands(pre_le7_nbr).addBands(pre_le7_ndvi).addBands(pre_le7_ndii)\n",
    "\n",
    "    #-------now do post-fire\n",
    "    #select bands\n",
    "    post_le7 = le7.filterDate(post_start, post_end).map(mask).map(land_scale).select(['SR_B1', 'SR_B2', 'SR_B3', 'SR_B4', 'SR_B5', 'SR_B7']).map(to_float)\n",
    "    #       #ensure we have imagery for the sensor\n",
    "    if post_le7.size().getInfo() > 0 :\n",
    "\n",
    "\n",
    "        #take the median\n",
    "        post_le7 = post_le7.median().clip(geometry)\n",
    "\n",
    "        #calculate nbr, ndvi and ndii\n",
    "        post_le7_nbr = post_le7.normalizedDifference(['SR_B4', 'SR_B7']).select([0], ['NBR']).cast({'NBR': 'float'})\n",
    "        post_le7_ndvi = post_le7.normalizedDifference(['SR_B4', 'SR_B3']).select([0], ['NDVI']).cast({'NDVI': 'float'})\n",
    "        post_le7_ndii = post_le7.normalizedDifference(['SR_B4', 'SR_B5']).select([0], ['NDII']).cast({'NDII': 'float'})\n",
    "\n",
    "        #add the bands back\n",
    "        post_le72 = post_le7.addBands(post_le7_nbr).addBands(post_le7_ndvi).addBands(post_le7_ndii)\n",
    "\n",
    "    #------------------------------------------Landsat 8 corrections\n",
    "\n",
    "\n",
    "    #-------first do pre-fire\n",
    "\n",
    "    #select bands\n",
    "    pre_lc8 = lc8.filterDate(pre_start, pre_end).map(mask).map(land_scale).select(['SR_B2','SR_B3','SR_B4','SR_B5','SR_B6','SR_B7'],['SR_B1', 'SR_B2', 'SR_B3', 'SR_B4', 'SR_B5', 'SR_B7']) .map(to_float)\n",
    "\n",
    "    #       #ensure we have imagery for the sensor\n",
    "    if pre_lc8.size().getInfo() > 0 :\n",
    "\n",
    "\n",
    "\n",
    "        #take the median\n",
    "        pre_lc8 = pre_lc8.median().clip(geometry)\n",
    "\n",
    "        #calculate nbr, ndvi and ndii\n",
    "        pre_lc8_nbr = pre_lc8.normalizedDifference(['SR_B4', 'SR_B7']).select([0], ['NBR']).cast({'NBR': 'float'})\n",
    "        pre_lc8_ndvi = pre_lc8.normalizedDifference(['SR_B4', 'SR_B3']).select([0], ['NDVI']).cast({'NDVI': 'float'})\n",
    "        pre_lc8_ndii = pre_lc8.normalizedDifference(['SR_B4', 'SR_B5']).select([0], ['NDII']).cast({'NDII': 'float'})\n",
    "\n",
    "        #add the bands back\n",
    "        pre_lc8 = pre_lc8.addBands(pre_lc8_nbr).addBands(pre_lc8_ndvi).addBands(pre_lc8_ndii)\n",
    "\n",
    "        #apply the corrections\n",
    "\n",
    "        l8_pre_corr = pre_lc8.multiply(l8_corr[1]).add(pre_lc8.pow(2).multiply(l8_corr[2])).add(pre_lc8.pow(3).multiply(l8_corr[3])).add(l8_corr[0])\n",
    "\n",
    "    #-------now do post-fire\n",
    "    #select bands\n",
    "    post_lc8 = lc8.filterDate(post_start, post_end).map(mask).map(land_scale).select(['SR_B2','SR_B3','SR_B4','SR_B5','SR_B6','SR_B7'],['SR_B1', 'SR_B2', 'SR_B3', 'SR_B4', 'SR_B5', 'SR_B7']) .map(to_float)\n",
    "\n",
    "    #       #ensure we have imagery for the sensor\n",
    "    if post_lc8.size().getInfo() > 0 :\n",
    "\n",
    "\n",
    "\n",
    "        #take the median\n",
    "        post_lc8 = post_lc8.median().clip(geometry)\n",
    "\n",
    "        #calculate nbr, ndvi and ndii\n",
    "        post_lc8_nbr = post_lc8.normalizedDifference(['SR_B4', 'SR_B7']).select([0], ['NBR']).cast({'NBR': 'float'})\n",
    "        post_lc8_ndvi = post_lc8.normalizedDifference(['SR_B4', 'SR_B3']).select([0], ['NDVI']).cast({'NDVI': 'float'})\n",
    "        post_lc8_ndii = post_lc8.normalizedDifference(['SR_B4', 'SR_B5']).select([0], ['NDII']).cast({'NDII': 'float'})\n",
    "\n",
    "        #add the bands back\n",
    "        post_lc8 = post_lc8.addBands(post_lc8_nbr).addBands(post_lc8_ndvi).addBands(post_lc8_ndii)\n",
    "\n",
    "        #apply the corrections\n",
    "\n",
    "        l8_post_corr = post_lc8.multiply(l8_corr[1]).add(post_lc8.pow(2).multiply(l8_corr[2])).add(post_lc8.pow(3).multiply(l8_corr[3])).add(l8_corr[0])\n",
    "\n",
    "        # #          #------------------------------------------Sentinel 2 corrections, use landsat 8 coefficients\n",
    "\n",
    "\n",
    "    ##-------first do pre-fire\n",
    "\n",
    "    #select bands\n",
    "    pre_sent = sent_2A.filterDate(pre_start, pre_end).map(sent_scale).select(['SR_B1', 'SR_B2', 'SR_B3', 'SR_B4', 'SR_B5', 'SR_B7']).map(to_float)\n",
    "\n",
    "    #       #ensure we have imagery for the sensor\n",
    "    if pre_sent.size().getInfo() > 0 :\n",
    "\n",
    "\n",
    "\n",
    "          #take the median\n",
    "        pre_sent = pre_sent.median().clip(geometry)\n",
    "\n",
    "        #calculate nbr, ndvi and ndii\n",
    "        pre_sent_nbr = pre_sent.normalizedDifference(['SR_B4', 'SR_B7']).select([0], ['NBR']).cast({'NBR': 'float'})\n",
    "        pre_sent_ndvi = pre_sent.normalizedDifference(['SR_B4', 'SR_B3']).select([0], ['NDVI']).cast({'NDVI': 'float'})\n",
    "        pre_sent_ndii = pre_sent.normalizedDifference(['SR_B4', 'SR_B5']).select([0], ['NDII']).cast({'NDII': 'float'})\n",
    "\n",
    "        #add the bands back\n",
    "        pre_sent = pre_sent.addBands(pre_sent_nbr).addBands(pre_sent_ndvi).addBands(pre_sent_ndii)\n",
    "\n",
    "        #apply the corrections\n",
    "\n",
    "        sent_pre_corr = pre_sent.multiply(l8_corr[1]).add(pre_sent.pow(2).multiply(l8_corr[2])).add(pre_sent.pow(3).multiply(l8_corr[3])).add(l8_corr[0])\n",
    "\n",
    "    #-------now do post-fire\n",
    "    #select bands\n",
    "    post_sent = sent_2A.filterDate(post_start, post_end).map(sent_scale).select(['SR_B1', 'SR_B2', 'SR_B3', 'SR_B4', 'SR_B5', 'SR_B7']).map(to_float)\n",
    "\n",
    "    #       #ensure we have imagery for the sensor\n",
    "    if post_sent.size().getInfo() > 0 :\n",
    "\n",
    "\n",
    "\n",
    "        #take the median\n",
    "        post_sent = post_sent.median().clip(geometry)\n",
    "\n",
    "        #calculate nbr, ndvi and ndii\n",
    "        post_sent_nbr = post_sent.normalizedDifference(['SR_B4', 'SR_B7']).select([0], ['NBR']).cast({'NBR': 'float'})\n",
    "        post_sent_ndvi = post_sent.normalizedDifference(['SR_B4', 'SR_B3']).select([0], ['NDVI']).cast({'NDVI': 'float'})\n",
    "        post_sent_ndii = post_sent.normalizedDifference(['SR_B4', 'SR_B5']).select([0], ['NDII']).cast({'NDII': 'float'})\n",
    "\n",
    "        #add the bands back\n",
    "        post_sent = post_sent.addBands(post_sent_nbr).addBands(post_sent_ndvi).addBands(post_sent_ndii)\n",
    "\n",
    "        #apply the corrections\n",
    "\n",
    "        sent_post_corr = post_sent.multiply(l8_corr[1]).add(post_sent.pow(2).multiply(l8_corr[2])).add(post_sent.pow(3).multiply(l8_corr[3])).add(l8_corr[0])\n",
    "\n",
    "\n",
    "    #try to see if image exists, if so append\n",
    "\n",
    "    #----------------------all prefire\n",
    "\n",
    "    #       #empty list for pre-fire, use this to combine if we have land 5, 7, 8 or sentinel\n",
    "    pre_input = []\n",
    "\n",
    "    try:\n",
    "        l5_pre_corr.getInfo()\n",
    "        pre_input.append(l5_pre_corr)\n",
    "\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "    try:\n",
    "        pre_le72.getInfo()\n",
    "        pre_input.append(pre_le72)\n",
    "\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "    try:\n",
    "        l8_pre_corr.getInfo()\n",
    "        pre_input.append(l8_pre_corr)\n",
    "\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "    try:\n",
    "        sent_pre_corr.getInfo()\n",
    "        pre_input.append(sent_pre_corr)\n",
    "\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "\n",
    "    #----------------------all postfire\n",
    "\n",
    "    #         #       #empty list for post-fire, use this to combine if we have land 5, 7, 8 or sentinel\n",
    "    post_input = []\n",
    "\n",
    "    try:\n",
    "        l5_post_corr.getInfo()\n",
    "        post_input.append(l5_post_corr)\n",
    "\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "    try:\n",
    "        post_le72.getInfo()\n",
    "        post_input.append(post_le72)\n",
    "\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "    try:\n",
    "        l8_post_corr.getInfo()\n",
    "        post_input.append(l8_post_corr)\n",
    "\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "    try:\n",
    "        sent_post_corr.getInfo()\n",
    "        post_input.append(sent_post_corr)\n",
    "\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "    #return the two lists of pre input and post input\n",
    "    return pre_input, post_input\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d56fa7f-e8f0-4682-ad14-d62546e14d3e",
   "metadata": {},
   "source": [
    "loop through all fires and get the imagery for the fires"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e9e80a9-0974-4a2e-a6ad-24f0084560cb",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading nbac_monthly/median_2497.tif\n",
      "Downloading nbac_monthly/median_4628.tif\n",
      "Downloading nbac_monthly/median_6169.tif\n",
      "Downloading nbac_monthly/median_10045.tif\n",
      "Downloading nbac_monthly/median_10849.tif\n",
      "Downloading nbac_monthly/median_11241.tif\n",
      "Downloading nbac_monthly/median_11201.tif\n",
      "Downloading nbac_monthly/median_11207.tif\n",
      "Downloading nbac_monthly/median_11237.tif\n",
      "Downloading nbac_monthly/median_379.tif\n",
      "Downloading nbac_monthly/median_375.tif\n",
      "Downloading nbac_monthly/median_50.tif\n",
      "Downloading nbac_monthly/median_142.tif\n",
      "Downloading nbac_monthly/median_263.tif\n",
      "Downloading nbac_monthly/median_389.tif\n",
      "Downloading nbac_monthly/median_374.tif\n",
      "Downloading nbac_monthly/median_387.tif\n",
      "Downloading nbac_monthly/median_95.tif\n",
      "Downloading nbac_monthly/median_486.tif\n",
      "Downloading nbac_monthly/median_444.tif\n",
      "Downloading nbac_monthly/median_578.tif\n",
      "Downloading nbac_monthly/median_736.tif\n",
      "Downloading nbac_monthly/median_757.tif\n",
      "Downloading nbac_monthly/median_787.tif\n",
      "Downloading nbac_monthly/median_795.tif\n",
      "Downloading nbac_monthly/median_932.tif\n",
      "Downloading nbac_monthly/median_1435.tif\n",
      "Downloading nbac_monthly/median_1264.tif\n",
      "Downloading nbac_monthly/median_1298.tif\n",
      "Downloading nbac_monthly/median_1314.tif\n",
      "Downloading nbac_monthly/median_1220.tif\n",
      "Downloading nbac_monthly/median_1202.tif\n",
      "Downloading nbac_monthly/median_1364.tif\n",
      "Downloading nbac_monthly/median_1493.tif\n",
      "Downloading nbac_monthly/median_1296.tif\n",
      "Downloading nbac_monthly/median_1327.tif\n",
      "Downloading nbac_monthly/median_1695.tif\n",
      "Downloading nbac_monthly/median_1565.tif\n",
      "Downloading nbac_monthly/median_1757.tif\n",
      "Downloading nbac_monthly/median_1544.tif\n",
      "Downloading nbac_monthly/median_1545.tif\n",
      "Downloading nbac_monthly/median_1556.tif\n",
      "Downloading nbac_monthly/median_1559.tif\n",
      "Downloading nbac_monthly/median_1584.tif\n",
      "Downloading nbac_monthly/median_1595.tif\n",
      "Downloading nbac_monthly/median_1602.tif\n",
      "Downloading nbac_monthly/median_1615.tif\n",
      "Downloading nbac_monthly/median_1617.tif\n",
      "Downloading nbac_monthly/median_1620.tif\n",
      "Downloading nbac_monthly/median_1676.tif\n",
      "Downloading nbac_monthly/median_1681.tif\n",
      "Downloading nbac_monthly/median_1689.tif\n",
      "Downloading nbac_monthly/median_1696.tif\n",
      "Downloading nbac_monthly/median_1785.tif\n",
      "Downloading nbac_monthly/median_1796.tif\n",
      "Downloading nbac_monthly/median_1808.tif\n",
      "Downloading nbac_monthly/median_1580.tif\n",
      "Downloading nbac_monthly/median_1601.tif\n",
      "Downloading nbac_monthly/median_1781.tif\n",
      "Downloading nbac_monthly/median_1568.tif\n",
      "Downloading nbac_monthly/median_1577.tif\n",
      "Downloading nbac_monthly/median_1581.tif\n",
      "Downloading nbac_monthly/median_1570.tif\n",
      "Downloading nbac_monthly/median_1585.tif\n",
      "Downloading nbac_monthly/median_1603.tif\n",
      "Downloading nbac_monthly/median_1673.tif\n",
      "Downloading nbac_monthly/median_1794.tif\n",
      "Downloading nbac_monthly/median_1795.tif\n",
      "Downloading nbac_monthly/median_1822.tif\n",
      "Downloading nbac_monthly/median_1686.tif\n",
      "Downloading nbac_monthly/median_1683.tif\n",
      "Downloading nbac_monthly/median_1684.tif\n",
      "Downloading nbac_monthly/median_1887.tif\n",
      "Downloading nbac_monthly/median_1890.tif\n",
      "Downloading nbac_monthly/median_1912.tif\n",
      "Downloading nbac_monthly/median_1925.tif\n",
      "Downloading nbac_monthly/median_1940.tif\n",
      "Downloading nbac_monthly/median_1892.tif\n",
      "Downloading nbac_monthly/median_1895.tif\n",
      "Downloading nbac_monthly/median_1897.tif\n",
      "Downloading nbac_monthly/median_1896.tif\n",
      "Downloading nbac_monthly/median_1900.tif\n",
      "Downloading nbac_monthly/median_1937.tif\n",
      "Downloading nbac_monthly/median_1958.tif\n",
      "Downloading nbac_monthly/median_1907.tif\n",
      "Downloading nbac_monthly/median_1909.tif\n",
      "Downloading nbac_monthly/median_1917.tif\n",
      "Downloading nbac_monthly/median_1926.tif\n",
      "Downloading nbac_monthly/median_1929.tif\n",
      "Downloading nbac_monthly/median_1931.tif\n",
      "Downloading nbac_monthly/median_1975.tif\n",
      "Downloading nbac_monthly/median_1982.tif\n",
      "Downloading nbac_monthly/median_1889.tif\n",
      "Downloading nbac_monthly/median_1910.tif\n",
      "Downloading nbac_monthly/median_1981.tif\n",
      "Downloading nbac_monthly/median_2031.tif\n",
      "Downloading nbac_monthly/median_2184.tif\n",
      "Downloading nbac_monthly/median_2187.tif\n",
      "Downloading nbac_monthly/median_2339.tif\n",
      "Downloading nbac_monthly/median_2233.tif\n",
      "Downloading nbac_monthly/median_2354.tif\n",
      "Downloading nbac_monthly/median_2013.tif\n",
      "Downloading nbac_monthly/median_2182.tif\n",
      "Downloading nbac_monthly/median_2032.tif\n",
      "Downloading nbac_monthly/median_2598.tif\n",
      "Downloading nbac_monthly/median_2471.tif\n",
      "Downloading nbac_monthly/median_2481.tif\n",
      "Downloading nbac_monthly/median_2564.tif\n",
      "Downloading nbac_monthly/median_2640.tif\n",
      "Downloading nbac_monthly/median_2749.tif\n",
      "Downloading nbac_monthly/median_3086.tif\n",
      "Downloading nbac_monthly/median_3412.tif\n",
      "Downloading nbac_monthly/median_3150.tif\n",
      "Downloading nbac_monthly/median_3180.tif\n",
      "Downloading nbac_monthly/median_3462.tif\n",
      "Downloading nbac_monthly/median_3631.tif\n",
      "Downloading nbac_monthly/median_3670.tif\n",
      "Downloading nbac_monthly/median_3546.tif\n",
      "Downloading nbac_monthly/median_3634.tif\n",
      "Downloading nbac_monthly/median_3843.tif\n",
      "Downloading nbac_monthly/median_3885.tif\n",
      "Downloading nbac_monthly/median_3495.tif\n",
      "Downloading nbac_monthly/median_3508.tif\n",
      "Downloading nbac_monthly/median_4461.tif\n",
      "Downloading nbac_monthly/median_4463.tif\n",
      "Downloading nbac_monthly/median_4475.tif\n",
      "Downloading nbac_monthly/median_4516.tif\n",
      "Downloading nbac_monthly/median_4533.tif\n",
      "Downloading nbac_monthly/median_4559.tif\n",
      "Downloading nbac_monthly/median_4583.tif\n",
      "Downloading nbac_monthly/median_4590.tif\n",
      "Downloading nbac_monthly/median_4620.tif\n",
      "Downloading nbac_monthly/median_4692.tif\n",
      "Downloading nbac_monthly/median_4695.tif\n",
      "Downloading nbac_monthly/median_4697.tif\n",
      "Downloading nbac_monthly/median_4803.tif\n",
      "Downloading nbac_monthly/median_4824.tif\n",
      "Downloading nbac_monthly/median_4483.tif\n",
      "Downloading nbac_monthly/median_4484.tif\n",
      "Downloading nbac_monthly/median_4494.tif\n",
      "Downloading nbac_monthly/median_4506.tif\n",
      "Downloading nbac_monthly/median_4524.tif\n",
      "Downloading nbac_monthly/median_4531.tif\n",
      "Downloading nbac_monthly/median_4603.tif\n",
      "Downloading nbac_monthly/median_4686.tif\n",
      "Downloading nbac_monthly/median_4827.tif\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#get all the ids within the lfdb shapefile\n",
    "all_ids = ee.List(lfdb.distinct([\"ID\"]).aggregate_array(\"ID\"))\n",
    "all_ids = all_ids.getInfo()\n",
    "\n",
    "# all_ids = all_ids[0:2]\n",
    "\n",
    "pre_months = ['-04-01', '-05-01', '-06-01', '-07-01', '-08-01', '-09-01', '-06-01']\n",
    "end_months = ['-05-01', '-06-01', '-07-01', '-08-01', '-09-01', '-10-01', '-08-31']\n",
    "\n",
    "all_months = dict(zip(pre_months, end_months))\n",
    "\n",
    "# all_ids = [1]\n",
    "\n",
    "folder_name = 'nbac_monthly'\n",
    "\n",
    "#loop through each fire polygon\n",
    "for i in all_ids:\n",
    "\n",
    "    #name of output file\n",
    "    # fname = f\"median_{i}.tif\"\n",
    "    fname = f\"{folder_name}/median_{i}.tif\"\n",
    "\n",
    "\n",
    "    #check if file exists on my bucket, if it does skip\n",
    "    stats = storage.Blob(bucket=bucket, name=fname).exists(storage_client)\n",
    "    if stats == False:\n",
    "        \n",
    "        #get the fire polygon of interest\n",
    "        sub_shape = lfdb.filter(ee.Filter.eq(\"ID\", i))\n",
    "\n",
    "        #get all other fire ids that are not this one\n",
    "        not_fires = lfdb.filter(ee.Filter.neq(\"ID\", i))\n",
    "\n",
    "      \n",
    "        #first get the bounding box of the fire\n",
    "        bbox = sub_shape.geometry().bounds()\n",
    "\n",
    "\n",
    "        #offset the bounding box by a random number\n",
    "        # all_rands = [0.00, 0.02, -0.02]\n",
    "        all_rands = [0.00]\n",
    "\n",
    "\n",
    "        rand1 = random.sample(all_rands, 1)[0]\n",
    "        rand2 = random.sample(all_rands, 1)[0]\n",
    "\n",
    "        #offset applied\n",
    "        proj = ee.Projection(\"EPSG:4326\").translate(rand1, rand2)\n",
    "        \n",
    "        #for the bounding box apply the randomly selected offset\n",
    "        final_buffer = ee.Geometry.Polygon(bbox.coordinates(), proj).transform(proj)\n",
    "        \n",
    "        #this is a bit of a hack but we have two different bounding box sizes because when we export we need to use some additonal area to avoid cuttoffs\n",
    "        final_buffer2 = final_buffer.buffer(distance= 5000).bounds()\n",
    "\n",
    "        final_buffer = final_buffer.buffer(distance= 40000)#.bounds().transform(proj='EPSG:3413', maxError=1)\n",
    "    \n",
    "        #get the year of this fire\n",
    "        this_year = ee.Number(sub_shape.aggregate_array('Year').get(0))\n",
    "        \n",
    "        year = this_year.getInfo() \n",
    "        \n",
    "        pre_start = ee.Date.fromYMD(this_year.subtract(1), 6, 1)\n",
    "        pre_end = ee.Date.fromYMD(this_year.subtract(1), 8, 31)\n",
    "        post_start = pre_start.advance(2, 'year')\n",
    "        post_end = pre_end.advance(2, 'year')\n",
    "     \n",
    "        #just getting some date info here to ensure pre fire is one  year before and post fire is one year after the fire year of interest\n",
    "        startYear = pre_start.get('year')\n",
    "\n",
    "        #convert to client side\n",
    "        startYear = startYear.getInfo()  # local string\n",
    "        endYear = str(int(startYear) + 2)\n",
    "        startYear = str(startYear)\n",
    "\n",
    "        \n",
    "        #loop through all the months and use 85th percentile to download all data\n",
    "        all_months_images = []\n",
    "\n",
    "         #loop through all months \n",
    "        for m1, m2 in all_months.items():\n",
    "\n",
    "            if m1 == '-06-01' and m2 == '-08-31':\n",
    "\n",
    "                start_year = year - 1\n",
    "                end_year = year + 1\n",
    "\n",
    "            else:\n",
    "\n",
    "                start_year = year - 1\n",
    "                end_year = year\n",
    "\n",
    "\n",
    "\n",
    "            #get pre dates\n",
    "            pre_start = str(start_year) + m1\n",
    "            pre_end = str(start_year) + m2\n",
    "\n",
    "            #get post dates\n",
    "            post_start = str(end_year) + m1\n",
    "            post_end = str(end_year) + m2\n",
    "\n",
    "\n",
    "\n",
    "            #apply the function to get the pre_fire image and post_fire image\n",
    "            all_imagery = get_pre_post(pre_start, pre_end, post_start, post_end, final_buffer)\n",
    "\n",
    "            #return the pre and post fire input imagery lists\n",
    "            pre_input = all_imagery[0]\n",
    "            post_input = all_imagery[1]\n",
    "\n",
    "            #if the lists each are larger than 1 we have imagery\n",
    "            if (len(pre_input) >0) and (len(post_input) > 0):\n",
    "\n",
    "                #take the median of the image collections\n",
    "                pre_input = ee.ImageCollection(pre_input)\n",
    "                post_input = ee.ImageCollection(post_input)\n",
    "\n",
    "                #get median of images\n",
    "                pre_input = pre_input.median()\n",
    "                post_input= post_input.median()\n",
    "\n",
    "                #difference the bands\n",
    "                raw_bands = pre_input.subtract(post_input).multiply(1000)\n",
    "\n",
    "                b1 = raw_bands.select('SR_B1').cast({'SR_B1':'short'})\n",
    "                b2 = raw_bands.select('SR_B2').cast({'SR_B2':'short'})\n",
    "                b3 = raw_bands.select('SR_B3').cast({'SR_B3':'short'})\n",
    "                b4 = raw_bands.select('SR_B4').cast({'SR_B4':'short'})\n",
    "                b5 = raw_bands.select('SR_B5').cast({'SR_B5':'short'})\n",
    "                b6 = raw_bands.select('SR_B7').cast({'SR_B7':'short'})\n",
    "                b7 = raw_bands.select('NBR').cast({'NBR':'short'})\n",
    "                b8 = raw_bands.select('NDVI').cast({'NDVI':'short'})\n",
    "                b9 = raw_bands.select('NDII').cast({'NDII':'short'})\n",
    "\n",
    "                #combine all the bands\n",
    "                # raw_bands = b1.addBands(b2).addBands(b3).addBands(b4).addBands(b5).addBands(b6).addBands(b7).addBands(b8).addBands(b9)\n",
    "                raw_bands = b7.addBands(b8).addBands(b9)\n",
    "\n",
    "                all_months_images.append(raw_bands)\n",
    "\n",
    "\n",
    "        #append to all_days vi\n",
    "        raw_bands = ee.ImageCollection(all_months_images).reduce(ee.Reducer.percentile([85]))\n",
    "        \n",
    "        b1 = raw_bands.select('SR_B1_p85').cast({'SR_B1_p85':'short'}) #0\n",
    "        b2 = raw_bands.select('SR_B2_p85').cast({'SR_B2_p85':'short'}) #1\n",
    "        b3 = raw_bands.select('SR_B3_p85').cast({'SR_B3_p85':'short'}) #2\n",
    "        b4 = raw_bands.select('SR_B4_p85').cast({'SR_B4_p85':'short'}) #3\n",
    "        b5 = raw_bands.select('SR_B5_p85').cast({'SR_B5_p85':'short'}) #4\n",
    "        b6 = raw_bands.select('SR_B7_p85').cast({'SR_B7_p85':'short'}) #5\n",
    "        b7 = raw_bands.select('NBR_p85').cast({'NBR_p85':'short'}) #band 6 is dnbr is numpy\n",
    "        b8 = raw_bands.select('NDVI_p85').cast({'NDVI_p85':'short'}) #7\n",
    "        b9 = raw_bands.select('NDII_p85').cast({'NDII_p85':'short'}) #8\n",
    "\n",
    "\n",
    "        #if using all bands\n",
    "        raw_bands = b7.addBands(b8).addBands(b9)\n",
    "\n",
    "\n",
    "        raw_bands = raw_bands.clip(final_buffer)\n",
    "        \n",
    "        #we need to see which image ids from the entire lfdb are already included in the buffer\n",
    "        lfdb_filtered_orig = lfdb.filterBounds(final_buffer)\n",
    "\n",
    "        #ensure all fires are within the actual year of interest (this_year) and two years prior, otherwise ignore, this is to ensure we don't have nearby fires from previous years\n",
    "        first_year =  int(startYear) + 1\n",
    "        second_year =  int(startYear)\n",
    "        third_year =  int(startYear) - 1\n",
    "        fourth_year = int(startYear) + 2\n",
    "\n",
    "        lfdb_filtered = lfdb_filtered_orig.filter(ee.Filter.eq(\"Year\", year))\n",
    "\n",
    "        bad_filtered = lfdb_filtered_orig.filter(ee.Filter.Or(ee.Filter.eq(\"Year\", second_year), ee.Filter.eq(\"Year\", third_year), ee.Filter.eq(\"Year\", fourth_year)))\n",
    "\n",
    "\n",
    "        #get ids which are in image\n",
    "        all_ids_new = ee.List(lfdb_filtered.distinct([\"ID\"]).aggregate_array(\"ID\")).getInfo()\n",
    "\n",
    "\n",
    "        #remove ids from all dates which we do not need anymore\n",
    "        all_ids2 = [i for i in all_ids if i not in all_ids_new]\n",
    "\n",
    "        #area we have good fires\n",
    "        fire_rast = lfdb_filtered.reduceToImage(properties= ['ID'], reducer = ee.Reducer.first())\n",
    "\n",
    "        #areas we have fires from other years or nearby we don't want to use\n",
    "        bad_fire_rast = bad_filtered.reduceToImage(properties= ['ID'], reducer = ee.Reducer.first())\n",
    "\n",
    "        #change values to 1 for fire of interest\n",
    "        fire_rast = fire_rast.where(fire_rast.gt(0), 1)\n",
    "\n",
    "        #change values for bad fire raster to 1 as well\n",
    "        bad_fire_rast = bad_fire_rast.where(bad_fire_rast.gt(0), 1)\n",
    "\n",
    "        #if the fires overlap we want to keep those locations\n",
    "        bad_fire_rast = bad_fire_rast.where(bad_fire_rast.eq(1).And(fire_rast.eq(1)), 2).unmask(-999)\n",
    "\n",
    "        #rename to y for the fire raster\n",
    "        fire_rast = fire_rast.rename(['y'])\n",
    "\n",
    "        #copy the first values of raw_bands\n",
    "        y = raw_bands.select(['NBR_p85'], ['y'])\n",
    "\n",
    "        #turn all values of y to 0\n",
    "        y  = y.where(y.gt(-10000), 0)\n",
    "\n",
    "        #turn values to 1 where fire_rast is 1\n",
    "        y  = y.where(fire_rast.eq(1), 1)\n",
    "\n",
    "        # #we need to ensure all bands are shorts \n",
    "        # b1 = raw_bands.select('SR_B1').cast({'SR_B1':'short'}) \n",
    "        # b2 = raw_bands.select('SR_B2').cast({'SR_B2':'short'}) \n",
    "        # b3 = raw_bands.select('SR_B3').cast({'SR_B3':'short'}) \n",
    "        # b4 = raw_bands.select('SR_B4').cast({'SR_B4':'short'}) \n",
    "        # b5 = raw_bands.select('SR_B5').cast({'SR_B5':'short'}) \n",
    "        # b6 = raw_bands.select('SR_B7').cast({'SR_B7':'short'}) \n",
    "        # b7 = raw_bands.select('NBR').cast({'NBR':'short'}) \n",
    "        # b8 = raw_bands.select('NDVI').cast({'NDVI':'short'}) \n",
    "        # b9 = raw_bands.select('NDII').cast({'NDII':'short'}) \n",
    "        b10 = y.select('y').cast({'y':'short'})\n",
    "\n",
    "        #combine all the bands for predictors\n",
    "        # raw_bands = b1.addBands(b2).addBands(b3).addBands(b4).addBands(b5).addBands(b6).addBands(b7).addBands(b8).addBands(b9)\n",
    "        # raw_bands = b1.addBands(b2).addBands(b3).addBands(b4).addBands(b5).addBands(b6).addBands(b7).addBands(b8).addBands(b9)\n",
    "\n",
    "        #for areas where there are nearby fires or fires in previous years we set those to 0\n",
    "        raw_bands = raw_bands.updateMask(bad_fire_rast.neq(1))\n",
    "\n",
    "        #add in the target variable\n",
    "        raw_bands = raw_bands.addBands(b10)\n",
    "\n",
    "        #start download\n",
    "        print(f\"Downloading {fname}\")\n",
    "\n",
    "\n",
    "        #export image to my cloud storage\n",
    "        task = ee.batch.Export.image.toCloudStorage(\n",
    "                                image = raw_bands.toShort(),\n",
    "                                region=final_buffer2, \n",
    "                                description='median_' + str(i),\n",
    "                                scale=30,\n",
    "                                crs='EPSG:3413',\n",
    "                                maxPixels=1e13,\n",
    "                                bucket = 'smp-scratch',\n",
    "                                fileNamePrefix=fname)\n",
    "\n",
    "        task.start()\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b03db704-5388-4eb0-8bf2-3067fa6ab573",
   "metadata": {},
   "outputs": [],
   "source": [
    "'t'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "430d2bf1-8dda-4786-af84-d2b07ff37882",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use reduceRegion to calculate the minimum and maximum values in the specified ROI\n",
    "stats = raw_bands.select('NBR_p85').reduceRegion(\n",
    "    reducer=ee.Reducer.minMax(),\n",
    "    geometry=final_buffer,\n",
    "    scale=30,  # Set the scale according to the resolution of the image\n",
    "    maxPixels=1e9  # Adjust maxPixels as needed\n",
    ")\n",
    "\n",
    "# Get the minimum and maximum values\n",
    "min_value = stats.getNumber('NBR_p85_min')\n",
    "max_value = stats.getNumber('NBR_p85_max')\n",
    "\n",
    "# Print the results\n",
    "print('Minimum Value:', min_value.getInfo())\n",
    "print('Maximum Value:', max_value.getInfo())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1af3ff1c-e887-42f8-8d7d-3972111d0435",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:.conda-gee_ml]",
   "language": "python",
   "name": "conda-env-.conda-gee_ml-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
